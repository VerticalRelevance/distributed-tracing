2025-02-05 15:41:38,244 - DEBUG - start __main__
2025-02-05 15:41:38,273 - DEBUG - source_path: /Users/scaswell/VerticalRelevance/Projects/Internal/Trace-Injection/distributed-tracing/src/analyze_source_ast-keep-250131.py
2025-02-05 15:41:38,273 - DEBUG - start process_file
2025-02-05 15:41:38,273 - DEBUG - input_source_path: /Users/scaswell/VerticalRelevance/Projects/Internal/Trace-Injection/distributed-tracing/src/analyze_source_ast-keep-250131.py
2025-02-05 15:41:38,273 - DEBUG - start get_source_code
2025-02-05 15:41:38,274 - DEBUG - end get_source_code
2025-02-05 15:41:38,274 - DEBUG - full_code len: 12888
2025-02-05 15:41:38,276 - DEBUG - source_tree class: SourceCodeNode name: SourceCodeNode
2025-02-05 15:41:38,276 - DEBUG - start tree_dumps
2025-02-05 15:41:38,276 - DEBUG - tree_dumps type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start _tree_to_str
2025-02-05 15:41:38,276 - DEBUG - _tree_to_str type(node): <class '__main__.SourceCodeNode'>
2025-02-05 15:41:38,276 - DEBUG - start extract_functions
2025-02-05 15:41:38,276 - DEBUG - type(code): <class 'str'>
2025-02-05 15:41:38,276 - DEBUG - Extracting functions from code
2025-02-05 15:41:38,277 - DEBUG - node:
2025-02-05 15:41:38,277 - DEBUG - {'name': '__init__', 'args': <ast.arguments object at 0x10535f510>, 'body': [<ast.Expr object at 0x10535f450>, <ast.Expr object at 0x10535f110>], 'decorator_list': [], 'returns': None, 'type_comment': None, 'type_params': [], 'lineno': 30, 'col_offset': 4, 'end_lineno': 32, 'end_col_offset': 31}
2025-02-05 15:41:38,277 - DEBUG - node:
2025-02-05 15:41:38,277 - DEBUG - {'name': 'is_silent', 'args': <ast.arguments object at 0x10535ef90>, 'body': [<ast.Return object at 0x10535ef10>], 'decorator_list': [], 'returns': <ast.Name object at 0x10535ee50>, 'type_comment': None, 'type_params': [], 'lineno': 35, 'col_offset': 4, 'end_lineno': 36, 'end_col_offset': 26}
2025-02-05 15:41:38,277 - DEBUG - node:
2025-02-05 15:41:38,277 - DEBUG - {'name': 'set_silent', 'args': <ast.arguments object at 0x10535edd0>, 'body': [<ast.Assign object at 0x10535ecd0>], 'decorator_list': [], 'returns': <ast.Constant object at 0x10535eb50>, 'type_comment': None, 'type_params': [], 'lineno': 39, 'col_offset': 4, 'end_lineno': 40, 'end_col_offset': 28}
2025-02-05 15:41:38,277 - DEBUG - node:
2025-02-05 15:41:38,277 - DEBUG - {'name': 'get_completion_with_retry', 'args': <ast.arguments object at 0x10535ea50>, 'body': [<ast.Expr object at 0x10535e610>, <ast.For object at 0x10535c4d0>], 'decorator_list': [], 'returns': None, 'type_comment': None, 'type_params': [], 'lineno': 42, 'col_offset': 4, 'end_lineno': 83, 'end_col_offset': 25}
2025-02-05 15:41:38,277 - DEBUG - node:
2025-02-05 15:41:38,277 - DEBUG - {'name': 'analyze_function_for_decision_points', 'args': <ast.arguments object at 0x1052ffa90>, 'body': [<ast.Expr object at 0x1052fff90>, <ast.Assign object at 0x105312dd0>, <ast.Assign object at 0x105310050>, <ast.If object at 0x105310c90>, <ast.If object at 0x105311010>, <ast.Assign object at 0x105311410>, <ast.Expr object at 0x105311a90>, <ast.Expr object at 0x105313e90>, <ast.Expr object at 0x1052f3750>, <ast.Expr object at 0x1052f2050>], 'decorator_list': [], 'returns': None, 'type_comment': None, 'type_params': [], 'lineno': 86, 'col_offset': 4, 'end_lineno': 129, 'end_col_offset': 77}
2025-02-05 15:41:38,277 - DEBUG - node:
2025-02-05 15:41:38,277 - DEBUG - {'name': 'process_file', 'args': <ast.arguments object at 0x1052f2450>, 'body': [<ast.Expr object at 0x1052f28d0>, <ast.Expr object at 0x1052f2c50>, <ast.Expr object at 0x1052f3350>, <ast.Expr object at 0x1052f36d0>, <ast.Assign object at 0x1052f2dd0>, <ast.Try object at 0x10534bf90>, <ast.If object at 0x105322d50>, <ast.Try object at 0x1053234d0>, <ast.Expr object at 0x10532a590>, <ast.Return object at 0x10532a990>], 'decorator_list': [], 'returns': None, 'type_comment': None, 'type_params': [], 'lineno': 132, 'col_offset': 4, 'end_lineno': 219, 'end_col_offset': 19}
2025-02-05 15:41:38,278 - DEBUG - node:
2025-02-05 15:41:38,278 - DEBUG - {'name': 'process_directory', 'args': <ast.arguments object at 0x10532a8d0>, 'body': [<ast.Expr object at 0x10532a050>, <ast.Expr object at 0x105329cd0>, <ast.If object at 0x105329bd0>, <ast.For object at 0x105328750>, <ast.Expr object at 0x105350b50>], 'decorator_list': [], 'returns': <ast.Constant object at 0x105350890>, 'type_comment': None, 'type_params': [], 'lineno': 223, 'col_offset': 4, 'end_lineno': 239, 'end_col_offset': 58}
2025-02-05 15:41:38,278 - DEBUG - Extracted 7 functions: __init__, is_silent, set_silent, get_completion_with_retry, analyze_function_for_decision_points, process_file, process_directory
2025-02-05 15:41:38,278 - DEBUG - end extract_functions
2025-02-05 15:41:38,278 - DEBUG - Extracted functions:
dict_keys(['__init__', 'is_silent', 'set_silent', 'get_completion_with_retry', 'analyze_function_for_decision_points', 'process_file', 'process_directory'])
2025-02-05 15:41:38,278 - DEBUG - Extracted function class:
2025-02-05 15:41:38,278 - DEBUG - {'__init__': <ast.FunctionDef object at 0x10535f550>,
 'analyze_function_for_decision_points': <ast.FunctionDef object at 0x1052ff990>,
 'get_completion_with_retry': <ast.FunctionDef object at 0x10535ead0>,
 'is_silent': <ast.FunctionDef object at 0x10535efd0>,
 'process_directory': <ast.FunctionDef object at 0x10532a910>,
 'process_file': <ast.FunctionDef object at 0x1052f2390>,
 'set_silent': <ast.FunctionDef object at 0x10535ee10>}
2025-02-05 15:41:38,278 - DEBUG - Extracted functions (new):
dict_keys([])
2025-02-05 15:41:38,278 - DEBUG - Extracted function (new) class:
2025-02-05 15:41:38,278 - DEBUG - {}
2025-02-05 15:41:38,278 - DEBUG - start extract_imports
2025-02-05 15:41:38,278 - DEBUG - Extracting imports from code
2025-02-05 15:41:38,280 - DEBUG - Extracted 9 imports: sys, os, Path, time, json, logging, openai, pformat, Utils
2025-02-05 15:41:38,280 - DEBUG - end extract_imports
2025-02-05 15:41:38,280 - DEBUG - Extracted imports:
dict_values([(<class 'ast.Import'>, 'sys'), (<class 'ast.Import'>, 'os'), (<class 'ast.ImportFrom'>, 'pathlib.Path'), (<class 'ast.Import'>, 'time'), (<class 'ast.Import'>, 'json'), (<class 'ast.Import'>, 'logging'), (<class 'ast.Import'>, 'openai'), (<class 'ast.ImportFrom'>, 'pprint.pformat'), (<class 'ast.ImportFrom'>, 'ast_utils.Utils')])
2025-02-05 15:41:38,280 - DEBUG - Extracted import class:
2025-02-05 15:41:38,280 - DEBUG - {'Path': <class 'ast.ImportFrom'>,
 'Utils': <class 'ast.ImportFrom'>,
 'json': <class 'ast.Import'>,
 'logging': <class 'ast.Import'>,
 'openai': <class 'ast.Import'>,
 'os': <class 'ast.Import'>,
 'pformat': <class 'ast.ImportFrom'>,
 'sys': <class 'ast.Import'>,
 'time': <class 'ast.Import'>}
2025-02-05 15:41:38,280 - DEBUG - start analyze_function_for_decision_points
2025-02-05 15:41:38,280 - DEBUG - start get_completion_with_retry
2025-02-05 15:41:38,280 - DEBUG - Get completion attempt: (attempt 1/10)
2025-02-05 15:41:38,280 - DEBUG - Input messages: 
Analyze the following Python source code and identify critical locations for adding trace statements based on these priorities:

Exception Handling Blocks, Function Entry/Exit Points, Complex Algorithm Sections, Performance-Critical Code Paths, State Changes, External Resource Interactions, Conditional Branches

Provide a detailed breakdown of:
1. Specific code blocks/lines to trace. Include the function/method name and parent if applicable.
2. Rationale for tracing
3. Recommended trace information to capture

Source Code:
```python
import sys
import os
from pathlib import Path
import time
import json
import logging
import openai
from pprint import pformat
from ast_utils import Utils


class SourceLocationTraceAnalyzer:
    # Class attributes

    MODEL = "gpt-4o-mini"

    # MAX_VLLM_RETRIES = 10  # maximum number of retries for the VLLM call
    MAX_VLLM_RETRIES = 3  # maximum number of retries for the VLLM call
    RETRY_DELAY = 0  # seconds
    # TEMPERATURE = 0.8  # 0.8 better than 1.0 better than 0.2
    TEMPERATURE = 0.0

    TOTAL_PROMPT_TOKENS = 0
    TOTAL_COMPLETION_TOKENS = 0

    client = openai.OpenAI()

    # Class methods

    def __init__(self, silent=False):
        Utils.setup_loggers(__name__, logging.INFO if not silent else logging.ERROR, logging.ERROR)
        self.set_silent(silent)

# TODO move to Utils?
    def is_silent(self) -> bool:
        return self.silent

# TODO move to Utils?
    def set_silent(self, silent: bool) -> None:
        self.silent = silent
    
    def get_completion_with_retry(self, messages, model, max_vllm_retries):
        Utils.stderr_logger.debug("start get_completion_with_retry")

        for attempt in range(max_vllm_retries):
            if not self.is_silent():
                Utils.stdout_logger.info(f"Get completion attempt: (attempt {attempt + 1}/{max_vllm_retries})")
            Utils.stderr_logger.debug(f"Get completion attempt: (attempt {attempt + 1}/{max_vllm_retries})")
            try:
                Utils.stderr_logger.debug(f"Input messages: {messages[-1]['content']}")
                chat_completion = SourceLocationTraceAnalyzer.client.chat.completions.create(
                    messages=messages,
                    model=model,
                    temperature=SourceLocationTraceAnalyzer.TEMPERATURE,
                )
                response = chat_completion.choices[0].message.content
                # Utils.stdout_logger.info(f"LLM response: {response}")
                if not self.is_silent():
                    Utils.stdout_logger.info("LLM response received")

                # Update token counts
                SourceLocationTraceAnalyzer.TOTAL_PROMPT_TOKENS += chat_completion.usage.prompt_tokens
                SourceLocationTraceAnalyzer.TOTAL_COMPLETION_TOKENS += chat_completion.usage.completion_tokens
                Utils.stderr_logger.debug("tokens:")
                Utils.stderr_logger.debug(pformat(chat_completion.usage))
                Utils.stderr_logger.debug(f"total tokens:")
                Utils.stderr_logger.debug(pformat(
                    {"total_prompt_tokens": SourceLocationTraceAnalyzer.TOTAL_PROMPT_TOKENS
                    ,"total_completion_tokens": SourceLocationTraceAnalyzer.TOTAL_COMPLETION_TOKENS
                }))
                Utils.stderr_logger.debug("end get_completion_with_retry")
                return response
            except Exception as e:
                if not self.is_silent():
                    Utils.stdout_logger.error(f"LLM call failed: {str(e)}")
                if attempt < max_vllm_retries - 1:
                    if not self.is_silent():
                        Utils.stdout_logger.info(f"Retrying in {SourceLocationTraceAnalyzer.RETRY_DELAY} seconds...")
                    time.sleep(SourceLocationTraceAnalyzer.RETRY_DELAY)
                else:
                    Utils.stdout_logger.error("Max retries reached. Giving up.")
                    Utils.stderr_logger.debug(f"end get_completion_with_retry raise Exception: {e}")
                    raise

    
    def analyze_function_for_decision_points(self, code):
        Utils.stderr_logger.debug("start analyze_function_for_decision_points")

        prompt = f"""
Analyze the following Python code. The Python code is contained below surrounded by backticks.
Identify decision points within the code. Decision points are statements such as if, elif, else, for, while.
Decision points are also source lines where flow control moves outside the current function.
Before performing the analysis, reconstruct the code as line-based text, with
each line terminated by a newline character.

In the response, include the decision point search term and the source line text where the search term was located.
Do not include any occurrences if contained in string literals.
Do not include any occurrences if contained on a commented source line.
Format the response as a valid JSON document.

```
{code}
```
        """

        messages = [
            {'role': 'system', 'content': 'You are an AI assistant specialized in code analysis.'},
            {'role': 'user', 'content': prompt},
        ]

        if "starcoder2" in SourceLocationTraceAnalyzer.MODEL.lower():
            # remove the system message
            messages = messages[1:]

        if not self.is_silent():
            Utils.stdout_logger.info("Analyzing code")
        response = self.get_completion_with_retry(messages, model=SourceLocationTraceAnalyzer.MODEL, max_vllm_retries=SourceLocationTraceAnalyzer.MAX_VLLM_RETRIES)
        Utils.stderr_logger.debug(f"LLM response: {response}")

        # text_blocks = Utils.extract_text_blocks(response)
        # if text_blocks:
        #     for block in text_blocks:
        #         Utils.stderr_logger.debug(f"Text block: {block}")
        #         if block.startswith("### Analysis"):
        #             Utils.stdout_logger.info(block)
        Utils.stdout_logger.info("Analysis complete")
        Utils.stdout_logger.info(response)

        Utils.stderr_logger.debug("end analyze_function_for_decision_points")

    
    def process_file(self, input_source_path: str):
        Utils.stderr_logger.debug("start process_file")
        Utils.stderr_logger.debug(f"input_source_path: {input_source_path}")
        Utils.stdout_logger.info("")
        Utils.stdout_logger.info(f"Process file '{input_source_path}'")

        # input_source_language = SourceLocationTraceAnalyzer.get_source_language(
        #     input_source_path
        # )
        # search_config = SourceLocationTraceAnalyzer.load_language_search_config(
        #     language=input_source_language
        # )
        # search_instructions = SourceLocationTraceAnalyzer.format_search_instructions(
        #     language_config=search_config
        # )

        # Utils.stderr_logger.debug("search_instructions:")
        # Utils.stderr_logger.debug(search_instructions)

        # llm_model = "gpt-3.5-turbo-0125"

#         system_content = """\
# You are an AI assistant specialized in analyzing Python functions and identifying critical decision points.

# The user is automation, so no additional explanation, summaries, or markdown formatting is required.
# """
        # messages = [
        #     {'role': 'system', 'content': system_content},
        #     {'role': 'user', 'content': search_instructions},
        # ]
        dependency_graph = None
        try:
            full_code = Utils.get_source_code(input_source_path)
            Utils.stderr_logger.debug(f"full_code len: {len(full_code)}")
            # Convert to tree-style hierarchical structure
            # hierarchical_code = SourceLocationTraceAnalyzer.convert_to_hierarchical(full_code, include_example=False)
            # Utils.stderr_logger.debug(f"Converted code to tree-style hierarchical structure:\n{hierarchical_code}")

            # Analyze the code
            # if not self.is_silent():
            #     self.analyze_code(full_code)

            # functions = Utils.extract_functions(hierarchical_code)
            functions = Utils.extract_functions(full_code)
            imports = Utils.extract_imports(full_code)
            Utils.stderr_logger.debug(f"Extracted functions:\n{pformat(functions.keys())}")
            Utils.stderr_logger.debug("Extracted function class:")
            Utils.stderr_logger.debug(pformat( {k: v[0] for k, v in functions.items()} ))
            Utils.stderr_logger.debug(f"Extracted imports:\n{pformat(imports.values())}")
            Utils.stderr_logger.debug("Extracted import class:")
            Utils.stderr_logger.debug(pformat( {k: v[0] for k, v in imports.items()} ))
            functions_and_imports = functions | imports

            # Create a dependency graph
            # dependency_graph = Utils.create_dependency_graph(functions)
            dependency_graph = Utils.create_dependency_graph(functions_and_imports)
            Utils.stderr_logger.debug(f"dependency_graph: {pformat(dependency_graph)}")
            Utils.stdout_logger.info(f"Dependency graph:\n{Utils.get_dependency_graph_str(dependency_graph)}")
        except Exception as e:
            Utils.stderr_logger.error(f"Failed to analyze code: {str(e)}", exc_info=True)
            return False

        if dependency_graph is None:
            Utils.stdout_logger.error("Failed to create dependency graph")
            return False

        try:
            # loop over functions
            for function_name, (_, function_code) in functions.items():
                Utils.stderr_logger.debug(f"function_name: {function_name}")
                Utils.stdout_logger.info(f"Function: {function_name}")

                # Convert to tree-style hierarchical structure
                # hierarchical_code = SourceLocationTraceAnalyzer.convert_to_hierarchical(function_code, include_example=False)
                # Utils.stderr_logger.debug(f"Converted code to tree-style hierarchical structure:\n{hierarchical_code}")

                # Analyze the code
                self.analyze_function_for_decision_points(function_code)
        except:
            Utils.stderr_logger.error(f"Failed to analyze code function '{function_name}'", exc_info=True)
            return False

        # # Sort functions based on their dependencies (bottom-up)
        # sorted_functions = Utils.topological_sort(dependency_graph)
        # Utils.stderr_logger.debug(f"sorted_functions: {sorted_functions}")

        Utils.stderr_logger.debug("end process_file")
        return True


    
    def process_directory(self, source_path: str) -> None:
        Utils.stderr_logger.debug("start process_directory")
        Utils.stderr_logger.debug(f"source_path: {source_path}")
        if not self.is_silent():
            Utils.stdout_logger.info(f"Process directory '{source_path}'")

        for root, dirs, files in Path(source_dir).walk():
            # Utils.stderr_logger.debug(pformat(path))
            Utils.stderr_logger.debug(f"root: {root}")
            Utils.stderr_logger.debug(f"dirs: {dirs}")
            Utils.stderr_logger.debug(f"files: {files}")
            for file in files:
                if file.endswith(".py"):
                    source_path = f"{root}/{file}"
                    self.process_file(source_path)

        Utils.stderr_logger.debug("end process_directory")

# Main loop to process file(s)
if __name__ == "__main__":
    # Get logging level from environment variable, default to INFO
    # Validate and set logging level
# TODO change default to DEBUG when finished development
    # log_level = os.getenv("LOG_LEVEL", "WARNING").upper()
    # level = getattr(logging, log_level, logging.WARNING)
    log_level = os.getenv("LOG_LEVEL", "DEBUG").upper()
    level = getattr(logging, log_level, logging.DEBUG)
    Utils.setup_loggers(name=Path(__file__).stem, logger_stderr_level = level)

    logging.getLogger("boto3").setLevel(logging.CRITICAL)
    logging.getLogger("botocore").setLevel(logging.CRITICAL)
    logging.getLogger("urllib3").setLevel(logging.CRITICAL)
    logging.getLogger("httpcore").setLevel(logging.CRITICAL)
    logging.getLogger("httpx").setLevel(logging.CRITICAL)

    Utils.stderr_logger.debug("start __main__")
    be_silent: bool = os.getenv("SILENT", "false").lower() == "True"

    analyzer: SourceLocationTraceAnalyzer = SourceLocationTraceAnalyzer(be_silent)
    analyzer.set_silent(be_silent)
    if not analyzer.is_silent():
        Utils.stdout_logger.info("Starting...")

    SourceLocationTraceAnalyzer.MODEL = Utils.get_ai_model()
    SourceLocationTraceAnalyzer.MAX_VLLM_RETRIES = Utils.get_max_vllm_retries()
    SourceLocationTraceAnalyzer.TEMPERATURE = Utils.get_temperature()

    source_file = os.getenv("SOURCE_FILE")
    if source_file:
        Utils.stderr_logger.debug(f"source_file: {source_file}")
        analyzer.process_file(input_source_path=source_file)
    else:
        Utils.stderr_logger.debug("SOURCE_FILE not set")
        source_dir = os.getenv("SOURCE_DIR")
        if source_dir:
            Utils.stderr_logger.debug(f"source_dir: {source_dir}")
            analyzer.process_directory(source_dir)
        else:
            Utils.stderr_logger.debug("SOURCE_DIR not set")
            msg = "Please set either SOURCE_FILE or SOURCE_DIR environment variable."
            Utils.stderr_logger.error(msg)
            raise ValueError(msg)

    Utils.stderr_logger.debug("end __main__")

```

2025-02-05 15:41:51,075 - DEBUG - tokens:
2025-02-05 15:41:51,075 - DEBUG - CompletionUsage(completion_tokens=1034, prompt_tokens=2750, total_tokens=3784, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))
2025-02-05 15:41:51,075 - DEBUG - total tokens:
2025-02-05 15:41:51,076 - DEBUG - {'total_completion_tokens': 1034, 'total_prompt_tokens': 2750}
2025-02-05 15:41:51,076 - DEBUG - end get_completion_with_retry
2025-02-05 15:41:51,076 - DEBUG - LLM response: To effectively add trace statements to the provided Python source code, we will focus on the critical locations based on the specified priorities: Exception Handling Blocks, Function Entry/Exit Points, Complex Algorithm Sections, Performance-Critical Code Paths, State Changes, External Resource Interactions, and Conditional Branches. Below is a detailed breakdown of specific code blocks/lines to trace, the rationale for tracing, and the recommended trace information to capture.

### 1. Exception Handling Blocks

**Code Block:**
```python
try:
    # Code that may raise an exception
except Exception as e:
    Utils.stderr_logger.error(f"Failed to analyze code: {str(e)}", exc_info=True)
```

**Rationale for Tracing:**
- Exception handling is critical for understanding failures in the application. Tracing here will help identify the context of errors.

**Recommended Trace Information:**
- Capture the exception type and message.
- Include the stack trace for better debugging.
- Log the state of relevant variables at the time of the exception.

### 2. Function Entry/Exit Points

**Code Block:**
```python
def get_completion_with_retry(self, messages, model, max_vllm_retries):
    Utils.stderr_logger.debug("start get_completion_with_retry")
    # Function logic
    Utils.stderr_logger.debug("end get_completion_with_retry")
```

**Rationale for Tracing:**
- Tracing function entry and exit points helps in monitoring the flow of execution and understanding the performance of the application.

**Recommended Trace Information:**
- Log the function name, parameters received, and any relevant state information at entry.
- Log the return value or outcome at exit.

### 3. Complex Algorithm Sections

**Code Block:**
```python
for function_name, (_, function_code) in functions.items():
    self.analyze_function_for_decision_points(function_code)
```

**Rationale for Tracing:**
- This section involves iterating over functions and analyzing them, which can be complex and may have performance implications.

**Recommended Trace Information:**
- Log the function name being analyzed.
- Capture the length or complexity of the function code being processed.

### 4. Performance-Critical Code Paths

**Code Block:**
```python
chat_completion = SourceLocationTraceAnalyzer.client.chat.completions.create(
    messages=messages,
    model=model,
    temperature=SourceLocationTraceAnalyzer.TEMPERATURE,
)
```

**Rationale for Tracing:**
- This line interacts with an external API, which can be a performance bottleneck. Tracing here can help identify latency issues.

**Recommended Trace Information:**
- Log the start and end time of the API call.
- Capture the size of the request and response payloads.

### 5. State Changes

**Code Block:**
```python
SourceLocationTraceAnalyzer.TOTAL_PROMPT_TOKENS += chat_completion.usage.prompt_tokens
SourceLocationTraceAnalyzer.TOTAL_COMPLETION_TOKENS += chat_completion.usage.completion_tokens
```

**Rationale for Tracing:**
- State changes in token counts are important for understanding the usage of the model and can impact billing or performance.

**Recommended Trace Information:**
- Log the previous and new values of `TOTAL_PROMPT_TOKENS` and `TOTAL_COMPLETION_TOKENS`.

### 6. External Resource Interactions

**Code Block:**
```python
full_code = Utils.get_source_code(input_source_path)
```

**Rationale for Tracing:**
- This line reads from an external source (file system), which can fail or be slow.

**Recommended Trace Information:**
- Log the path being read and the size of the content read.
- Capture any errors encountered during the read operation.

### 7. Conditional Branches

**Code Block:**
```python
if not self.is_silent():
    Utils.stdout_logger.info("Analyzing code")
```

**Rationale for Tracing:**
- Conditional branches can affect the flow of execution and the information logged.

**Recommended Trace Information:**
- Log the condition being evaluated and the outcome (true/false).
- Capture any relevant state information that influences the condition.

### Summary of Trace Locations

1. **Exception Handling Blocks**: Trace exceptions in `process_file` and `analyze_function_for_decision_points`.
2. **Function Entry/Exit Points**: Trace entry and exit in `get_completion_with_retry`, `analyze_function_for_decision_points`, and `process_file`.
3. **Complex Algorithm Sections**: Trace function analysis in `process_file`.
4. **Performance-Critical Code Paths**: Trace API calls in `get_completion_with_retry`.
5. **State Changes**: Trace token updates in `get_completion_with_retry`.
6. **External Resource Interactions**: Trace file reading in `process_file`.
7. **Conditional Branches**: Trace conditions in `process_directory` and other methods.

By implementing these trace statements, you will enhance the observability of the application, making it easier to diagnose issues and understand the flow of execution.
2025-02-05 15:41:51,076 - DEBUG - end analyze_function_for_decision_points
2025-02-05 15:41:51,076 - DEBUG - end process_file
2025-02-05 15:41:51,077 - DEBUG - end __main__
